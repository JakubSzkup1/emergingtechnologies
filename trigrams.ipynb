{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Third-order letter approximation model\n",
    "\n",
    "In this task, I will create a trigram model of the English language using five english works from Project Gutenberg."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Prepocessing the Text\n",
    "\n",
    "Text Prepocessing:\n",
    "The first step is to clean and preprocess the text. By doing this i aim to remove all unwanted characters, \n",
    "such as numbers and punctuations expect for fullstops and then convert everything into uppercasel.\n",
    "This will simplify the text and make it uniform, this will allow us to focus only on the sequence of letters,spaces and fullstops.\n",
    "\n",
    "Args:\n",
    "        text (str): The original text to be cleaned.\n",
    "\n",
    "Returns: \n",
    "        str: Cleaned and preprocessed text.\n",
    "\n",
    "I will use Pythons re module to handle the text cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Imports\n",
    "import re\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THIS IS A SAMPLE TEXT  IT WILL BE PREPROCESSED TO REMOVE ALL NON ALPHANUMERIC CHARACTERS            AND CONVERT ALL CHARACTERS TO UPPERCASE \n"
     ]
    }
   ],
   "source": [
    "# Function to preprocess the text\n",
    "def preprocess_text(text):\n",
    "    # Remove all non-alphanumeric characters with a space\n",
    "    clean_text = re.sub(r'[^a-zA-Z0-9]', ' ', text)\n",
    "    # Convert all characters to uppercase\n",
    "    clean_text = clean_text.upper()\n",
    "\n",
    "    return clean_text #Return the cleaned text\n",
    "\n",
    "# Test the function with a sample text\n",
    "text1 = \"This is a sample text. It will be preprocessed to remove all non-alphanumeric characters !!!!! ,,,, and convert all characters to uppercase.\"\n",
    "cleaned_text = preprocess_text(text1)\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explantion of output\n",
    "As you can see above, The text gets preprocessed and changed into all uppercase letters and a gap is also left where non-alphanumeric characters are removed.\n",
    "\n",
    "## Alphanumeric Characters\n",
    "Alphanumeric Characters refer to the combination of **letters (A-Z)** and **numbers (0-9)**, which would be used quiet commonly in computing for passwords, identifiers and any other text-based inputs where both letters and digits are needed.\n",
    "\n",
    "You can find more details in this article: [Alphanumeric Characters - TechTarget](https://www.techtarget.com/whatis/definition/alphanumeric-alphameric).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Creating the Trigram Model\n",
    "\n",
    "### Trigram Model:\n",
    "A trigram model captures the frequency of every three-character sequence in the text. \n",
    "In this step, I will build a dictionary where each key is a unique trigram and the corresponding value is the number of times that trigram appears in the text.\n",
    "\n",
    "I will use a defaultdict from Python's collections module.\n",
    "\n",
    "This approach is commonly used in **natural language processing (NLP)**, usually for tasks such as text prediction or even language modeling where n-grams, trigrams in this case are created to capture sequnce patterns.\n",
    "\n",
    "Reference: [N-grams in Natural Language Processing](https://en.wikipedia.org/wiki/N-gram)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def create_trigram_model(text):\n",
    "    trigram_counts = defaultdict(int)\n",
    "\n",
    "    # Loop over the text, extracting trigrams and updating their counts\n",
    "    for i in range(len(text) - 2):\n",
    "        trigram = text[i:i+3]\n",
    "        trigram_counts[trigram] += 1\n",
    "\n",
    "    return trigram_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function with sample text\n",
    "sample_text = \"hello world, This is a sample text to test the trigram model.\"\n",
    "trigram_counts = create_trigram_model(sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explantion of Output:\n",
    "If we take a look at the the sample word 'Hello'\n",
    "\n",
    "1. **'hell': 1** - This trigram appeared only once in the sample text.\n",
    "2. **'ell': 1** - This trigram also appeared only one time.\n",
    "3. **'llo': 1** - Once again this trigram only appeared once\n",
    "\n",
    "So basically, the frequency count of each of the trigrams gives us an insight into how common certain letter combinations appear in the text. This proves the trigram model to be useful for capturing patterns in sequences of text, which can be used for tasks such as text generation.\n",
    "\n",
    "In this sample output above we can see that sequences like 'is' appear more than once. However, more unique trigrams such as 'hell' or 'llo' appear only once. This model provides us with a foundation for predicting the next character in a sequence based on previous characters.\n",
    "\n",
    "#### Reference:\n",
    "1. **Understanding Language Modeling**: For a more detailed explanation of language models, including n-grams and transformer-based neural models, refer to this [Medium article](https://medium.com/@roshmitadey/understanding-language-modeling-from-n-grams-to-transformer-based-neural-models-d2bdf1532c6d)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'hel' : 1\n",
      "'ell' : 1\n",
      "'llo' : 1\n",
      "'lo ' : 1\n",
      "'o w' : 1\n",
      "' wo' : 1\n",
      "'wor' : 1\n",
      "'orl' : 1\n",
      "'rld' : 1\n",
      "'ld,' : 1\n",
      "'d, ' : 1\n",
      "', T' : 1\n",
      "' Th' : 1\n",
      "'Thi' : 1\n",
      "'his' : 1\n",
      "'is ' : 2\n",
      "'s i' : 1\n",
      "' is' : 1\n",
      "'s a' : 1\n",
      "' a ' : 1\n",
      "'a s' : 1\n",
      "' sa' : 1\n",
      "'sam' : 1\n",
      "'amp' : 1\n",
      "'mpl' : 1\n",
      "'ple' : 1\n",
      "'le ' : 1\n",
      "'e t' : 2\n",
      "' te' : 2\n",
      "'tex' : 1\n",
      "'ext' : 1\n",
      "'xt ' : 1\n",
      "'t t' : 2\n",
      "' to' : 1\n",
      "'to ' : 1\n",
      "'o t' : 1\n",
      "'tes' : 1\n",
      "'est' : 1\n",
      "'st ' : 1\n",
      "' th' : 1\n",
      "'the' : 1\n",
      "'he ' : 1\n",
      "' tr' : 1\n",
      "'tri' : 1\n",
      "'rig' : 1\n",
      "'igr' : 1\n",
      "'gra' : 1\n",
      "'ram' : 1\n",
      "'am ' : 1\n",
      "'m m' : 1\n",
      "' mo' : 1\n",
      "'mod' : 1\n",
      "'ode' : 1\n",
      "'del' : 1\n",
      "'el.' : 1\n"
     ]
    }
   ],
   "source": [
    "# Print the trigram counts\n",
    "for trigram, count in trigram_counts.items():\n",
    "    print(f\"'{trigram}' : {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Preprocessing the Text from Five Books\n",
    "\n",
    "Here we will load five books from Project Gutenberg and preprocess them and then combine them into single large text. Each book is read as plain text, cleaned to remove unwanted characters, and converted to uppercase using the `preprocess_text` function.\n",
    "\n",
    "#### Process:\n",
    "1. **Load Each Book**: Each book is loaded from the `texts/` folder.\n",
    "2. **Preprocess**: We clean the text by keeping only uppercase letters, spaces, and full stops.\n",
    "3. **Combine Text**: The preprocessed text from each book is combined into a single large string.\n",
    "\n",
    "Now, this combined text will serve as the basis for building the trigram model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined text length: 3666300 characters\n"
     ]
    }
   ],
   "source": [
    "# List of file paths for the five books inside the \"texts/\" folder\n",
    "books = [\"texts/book1.txt\", \"texts/book2.txt\", \"texts/book3.txt\", \"texts/book4.txt\", \"texts/book5.txt\"]\n",
    "\n",
    "# Preprocess all books and combine them into one large string\n",
    "combined_text = \"\"\n",
    "for book in books:\n",
    "    with open(book, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()  # Read the text of the book\n",
    "        clean_text = preprocess_text(text)  # Preprocess the text\n",
    "        combined_text += clean_text  # Combine all preprocessed texts\n",
    "\n",
    "# Check the length of the combined text\n",
    "print(f\"Combined text length: {len(combined_text)} characters\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, the length of the combined text is printed after being preprocessed to verify all text has been combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Trigram Model\n",
    "So now using the combined text, we create a trigram model taht captures th frequency of each trigram. The model will allow us to generate new text that mimics the the structure and style of the original books\n",
    "\n",
    "#### Process:\n",
    "- **Trigram Model**: We loop trough the combined text and count each unique trigram, the model is stored as a dictionary where each key is a trigram and the value is the amount of times the trigram appears.\n",
    "\n",
    "Below you can see the first 10 trigrams and their counts are displayed as a sample to inspect the structure of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' TH': 61066\n",
      "'THE': 46163\n",
      "'HE ': 45241\n",
      "'E P': 4706\n",
      "' PR': 5519\n",
      "'PRO': 3305\n",
      "'ROJ': 465\n",
      "'OJE': 464\n",
      "'JEC': 992\n",
      "'ECT': 3654\n"
     ]
    }
   ],
   "source": [
    "# Create the trigram model from the combined text\n",
    "trigram_model = create_trigram_model(combined_text)\n",
    "\n",
    "# Print the first 10 trigrams to inspect the model\n",
    "for trigram, count in list(trigram_model.items())[:10]:\n",
    "    print(f\"'{trigram}': {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Generating Text from the Trigram Model\n",
    "\n",
    "In this task, I will use the trigram model that I have created in Task 1 to generate a string of 10,000 characters. This process begins with a String of two characters ('TH'). For each subsequent character, we will look at the previous two characters and select the next character based on the trigrams that start with that string.\n",
    "\n",
    "We will choose the next character based on the frequency of the trigram in the model.\n",
    "### For example:\n",
    "If the model contains trigrams like 'THE', 'THA', and 'THI', the next character could be 'E', 'A', or 'I', with probabilties based on how many times they come up in the text.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the random module\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the next character based on the current bigram\n",
    "def get_next_char(trigram_model, current_bigram):\n",
    "    # Find all trigrams starting with the current bigram\n",
    "    possible_trigrams = {tri: count for tri, count in trigram_model.items() if tri.startswith(current_bigram)}\n",
    "\n",
    "    if not possible_trigrams:\n",
    "        return ' '\n",
    "    \n",
    "    # Extract the third character and the corresponding weights\n",
    "    next_chars = [tri[2] for tri in possible_trigrams.keys()]\n",
    "    weights = list(possible_trigrams.values())\n",
    "\n",
    "    # Randomly select the next character based on the weights (trigram frequencies)\n",
    "    return random.choices(next_chars, weights=weights)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating 10,000 Characters of Text\n",
    "Using the 'get_next_char' function we will build a string starting with 'TH' and for each step, the function will look at the last two characters and select the next character based on the trigram model.\n",
    "\n",
    "We will then generate a string of 10,000 characters by repeatedly calling the 'get_next_char' function.\n",
    "\n",
    "#### References:\n",
    "1. **Random Choices in Python**: The `random.choices()` method is used to select the next character based on trigram frequencies. Learn more about this function in the [Python documentation](https://docs.python.org/3/library/random.html#random.choices).\n",
    "2. **N-gram Models in Text Generation**: Learn how n-gram models are applied to text generation from this resource: [Stanford NLP](https://web.stanford.edu/~jurafsky/slp3/3.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a string of a specified length using the trigram model\n",
    "def generate_text(trigram_model, length=10000):\n",
    "       # Start with the \"TH\"\n",
    "    generated_text = \"TH\"\n",
    "\n",
    "\n",
    "     # Generate characters until the desired length is reached\n",
    "    while len(generated_text) < length:\n",
    "        # Get the last two characters \n",
    "        current_bigram = generated_text[-2:]\n",
    "        \n",
    "        # Get the next character using the trigram model\n",
    "        next_char = get_next_char(trigram_model, current_bigram)\n",
    "        \n",
    "        # Append the next character to the generated text\n",
    "        generated_text += next_char\n",
    "    \n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TH                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n"
     ]
    }
   ],
   "source": [
    "# Generate 10,000 characters of text using the trigram model\n",
    "generated_text = generate_text(trigram_counts, length=10000)\n",
    "\n",
    "# Print the first 500 characters to inspect the output\n",
    "print(generated_text[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
